{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bebb8332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b02f6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import time\n",
    "# import pandas as pd\n",
    "# from datetime import datetime, timedelta\n",
    "# from binance.client import Client\n",
    "# from binance.exceptions import BinanceAPIException\n",
    "# from requests.exceptions import ConnectionError\n",
    "\n",
    "# # â”€â”€ 1. CONFIGURATION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# API_KEY    = \"YOUR_BINANCE_API_KEY\"       # <<<â€“â€“ letakkan API key Anda\n",
    "# API_SECRET = \"YOUR_BINANCE_API_SECRET\"    # <<<â€“â€“ letakkan API secret Anda\n",
    "# SYMBOL     = \"BTCUSDT\"\n",
    "# INTERVAL   = Client.KLINE_INTERVAL_1HOUR  # hourly\n",
    "# START      = \"1 Jan, 2017\"                # tarik data sejak listing\n",
    "\n",
    "# # Delay antar panggilan (detik)\n",
    "# DELAY = 5\n",
    "# # Jumlah retry maksimum\n",
    "# MAX_RETRIES = 5\n",
    "\n",
    "# client = Client(API_KEY, API_SECRET)\n",
    "\n",
    "# # â”€â”€ 2. SAFE WRAPPERS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# def retry_api(func, *args, **kwargs):\n",
    "#     backoff = 1\n",
    "#     for i in range(MAX_RETRIES):\n",
    "#         try:\n",
    "#             result = func(*args, **kwargs)\n",
    "#             time.sleep(DELAY)\n",
    "#             return result\n",
    "#         except (ConnectionError, BinanceAPIException) as e:\n",
    "#             print(f\"âš ï¸ API error ({e}), retry {i+1}/{MAX_RETRIES} in {backoff}sâ€¦\")\n",
    "#             time.sleep(backoff)\n",
    "#             backoff *= 2\n",
    "#     raise RuntimeError(f\"Gagal setelah {MAX_RETRIES} retry pada {func.__name__}\")\n",
    "\n",
    "# def safe_get_klines(**kwargs):\n",
    "#     return retry_api(client.get_klines, **kwargs)\n",
    "\n",
    "# def safe_futures_funding_rate(**kwargs):\n",
    "#     return retry_api(client.futures_funding_rate, **kwargs)\n",
    "\n",
    "# def safe_aggregate_trades(**kwargs):\n",
    "#     return retry_api(client.aggregate_trades, **kwargs)\n",
    "\n",
    "# def safe_open_interest_history(**kwargs):\n",
    "#     return retry_api(client.futures_open_interest_history, **kwargs)\n",
    "\n",
    "# def safe_get_order_book(**kwargs):\n",
    "#     return retry_api(client.get_order_book, **kwargs)\n",
    "\n",
    "# # â”€â”€ 3. FETCH FUNCTIONS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# def fetch_full_ohlcv(symbol, interval, start_str):\n",
    "#     all_df = []\n",
    "#     last_time = pd.to_datetime(start_str)\n",
    "#     while True:\n",
    "#         klines = safe_get_klines(\n",
    "#             symbol=symbol,\n",
    "#             interval=interval,\n",
    "#             startTime=int(last_time.timestamp()*1000),\n",
    "#             limit=1000\n",
    "#         )\n",
    "#         if not klines:\n",
    "#             break\n",
    "#         df = pd.DataFrame(klines, columns=[\n",
    "#             \"open_time\",\"open\",\"high\",\"low\",\"close\",\"volume\",\n",
    "#             \"close_time\",\"quote_asset_volume\",\"num_trades\",\n",
    "#             \"taker_buy_base_vol\",\"taker_buy_quote_vol\",\"ignore\"\n",
    "#         ])\n",
    "#         df[\"open_time\"]  = pd.to_datetime(df[\"open_time\"], unit=\"ms\")\n",
    "#         df[\"close_time\"] = pd.to_datetime(df[\"close_time\"], unit=\"ms\")\n",
    "#         df = df.rename(columns={\"open_time\":\"timestamp\"})\n",
    "#         all_df.append(df)\n",
    "#         last_time = df[\"timestamp\"].iloc[-1] + timedelta(milliseconds=1)\n",
    "#         if last_time >= datetime.utcnow():\n",
    "#             break\n",
    "#     return pd.concat(all_df, ignore_index=True)\n",
    "\n",
    "# def fetch_full_funding(symbol, start_str):\n",
    "#     all_df = []\n",
    "#     last_time = pd.to_datetime(start_str)\n",
    "#     while True:\n",
    "#         fr = safe_futures_funding_rate(\n",
    "#             symbol=symbol,\n",
    "#             startTime=int(last_time.timestamp()*1000),\n",
    "#             limit=1000\n",
    "#         )\n",
    "#         if not fr:\n",
    "#             break\n",
    "#         df = pd.DataFrame(fr)\n",
    "#         df[\"fundingTime\"] = pd.to_datetime(df[\"fundingTime\"], unit=\"ms\")\n",
    "#         df[\"fundingRate\"] = df[\"fundingRate\"].astype(float)\n",
    "#         all_df.append(df[[\"fundingTime\",\"fundingRate\"]])\n",
    "#         last_time = df[\"fundingTime\"].iloc[-1] + timedelta(milliseconds=1)\n",
    "#         if last_time >= datetime.utcnow():\n",
    "#             break\n",
    "#     df_full = pd.concat(all_df, ignore_index=True)\n",
    "#     # resample per jam: ambil last fundingRate setiap jam\n",
    "#     df_full = (\n",
    "#         df_full\n",
    "#         .set_index(\"fundingTime\")\n",
    "#         .resample(\"1H\").last()\n",
    "#         .dropna()\n",
    "#         .reset_index()\n",
    "#         .rename(columns={\"fundingTime\":\"timestamp\"})\n",
    "#     )\n",
    "#     return df_full\n",
    "\n",
    "# def fetch_full_agg_trades(symbol, start_str):\n",
    "#     all_trades = []\n",
    "#     last_id = None\n",
    "#     start_ms = int(pd.to_datetime(start_str).timestamp()*1000)\n",
    "#     while True:\n",
    "#         params = {\"symbol\":symbol, \"limit\":1000, \"startTime\":start_ms}\n",
    "#         if last_id:\n",
    "#             params[\"fromId\"] = last_id + 1\n",
    "#         trades = safe_aggregate_trades(**params)\n",
    "#         if not trades:\n",
    "#             break\n",
    "#         df = pd.DataFrame(trades).rename(\n",
    "#             columns={\"a\":\"aggTradeId\",\"T\":\"tradeTime\",\"q\":\"qty\"}\n",
    "#         )\n",
    "#         df[\"tradeTime\"] = pd.to_datetime(df[\"tradeTime\"], unit=\"ms\")\n",
    "#         all_trades.append(df)\n",
    "#         last_id = df[\"aggTradeId\"].iloc[-1]\n",
    "#     df_full = pd.concat(all_trades, ignore_index=True)\n",
    "#     df_full[\"hour\"] = df_full[\"tradeTime\"].dt.floor(\"H\")\n",
    "#     agg = (\n",
    "#         df_full.groupby(\"hour\")\n",
    "#         .apply(lambda d: pd.Series({\n",
    "#             \"buy_vol\":  d.loc[~d[\"isBuyerMaker\"], \"qty\"].sum(),\n",
    "#             \"sell_vol\": d.loc[ d[\"isBuyerMaker\"], \"qty\"].sum()\n",
    "#         }))\n",
    "#         .reset_index()\n",
    "#         .rename(columns={\"hour\":\"timestamp\"})\n",
    "#     )\n",
    "#     return agg\n",
    "\n",
    "# def fetch_full_open_interest(symbol, start_str):\n",
    "#     all_df = []\n",
    "#     last_time = pd.to_datetime(start_str)\n",
    "#     while True:\n",
    "#         hist = safe_open_interest_history(\n",
    "#             symbol=symbol,\n",
    "#             period=\"1h\",\n",
    "#             startTime=int(last_time.timestamp()*1000),\n",
    "#             limit=1000\n",
    "#         )\n",
    "#         if not hist:\n",
    "#             break\n",
    "#         df = pd.DataFrame(hist)\n",
    "#         df[\"timestamp\"]     = pd.to_datetime(df[\"timestamp\"], unit=\"ms\")\n",
    "#         df[\"openInterest\"] = df[\"sumOpenInterest\"].astype(float)\n",
    "#         all_df.append(df[[\"timestamp\",\"openInterest\"]])\n",
    "#         last_time = df[\"timestamp\"].iloc[-1] + timedelta(milliseconds=1)\n",
    "#         if last_time >= datetime.utcnow():\n",
    "#             break\n",
    "#     return pd.concat(all_df, ignore_index=True)\n",
    "\n",
    "# def fetch_order_book_snapshot(symbol, limit=100):\n",
    "#     ob = safe_get_order_book(symbol=symbol, limit=limit)\n",
    "#     bids = pd.DataFrame(ob[\"bids\"], columns=[\"price\",\"qty\"]).astype(float)\n",
    "#     asks = pd.DataFrame(ob[\"asks\"], columns=[\"price\",\"qty\"]).astype(float)\n",
    "#     now = datetime.utcnow().replace(minute=0,second=0,microsecond=0)\n",
    "#     return pd.DataFrame([{\n",
    "#         \"timestamp\":   now,\n",
    "#         \"bid_depth\":   bids[\"qty\"].sum(),\n",
    "#         \"ask_depth\":   asks[\"qty\"].sum(),\n",
    "#         \"top_bid\":     bids[\"price\"].iloc[0],\n",
    "#         \"top_ask\":     asks[\"price\"].iloc[0]\n",
    "#     }])\n",
    "\n",
    "# # â”€â”€ 4. MAIN: EKSEKUSI & SIMPAN CSV â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# if __name__ == \"__main__\":\n",
    "#     os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "#     # 4.1 OHLCV\n",
    "#     df_ohlcv = fetch_full_ohlcv(SYMBOL, INTERVAL, START)\n",
    "#     df_ohlcv.to_csv(\"data/ohlcv.csv\", index=False)\n",
    "\n",
    "#     # 4.2 Funding Rate\n",
    "#     df_fr = fetch_full_funding(SYMBOL, START)\n",
    "#     df_fr.to_csv(\"data/funding_rate.csv\", index=False)\n",
    "\n",
    "#     # 4.3 Aggregate Trades\n",
    "#     df_trades = fetch_full_agg_trades(SYMBOL, START)\n",
    "#     df_trades.to_csv(\"data/agg_trades.csv\", index=False)\n",
    "\n",
    "#     # 4.4 Open Interest\n",
    "#     df_oi = fetch_full_open_interest(SYMBOL, START)\n",
    "#     df_oi.to_csv(\"data/open_interest.csv\", index=False)\n",
    "\n",
    "#     # 4.5 Order Book snapshot\n",
    "#     df_ob = fetch_order_book_snapshot(SYMBOL, limit=100)\n",
    "#     df_ob.to_csv(\"data/order_book.csv\", index=False)\n",
    "\n",
    "#     # 4.6 Merge semua berdasarkan timestamp (hourly)\n",
    "#     dfs = [\n",
    "#         df_ohlcv.set_index(\"timestamp\"),\n",
    "#         df_fr.set_index(\"timestamp\"),\n",
    "#         df_trades.set_index(\"timestamp\"),\n",
    "#         df_oi.set_index(\"timestamp\"),\n",
    "#         df_ob.set_index(\"timestamp\")\n",
    "#     ]\n",
    "#     df_combined = pd.concat(dfs, axis=1).reset_index()\n",
    "#     df_combined.to_csv(\"data/combined.csv\", index=False)\n",
    "\n",
    "#     print(\"âœ… Semua data off-chain per jam berhasil diambil, di-retry jika error, dan disimpan di ./data/\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca13582",
   "metadata": {},
   "source": [
    "Block 1 â€“ fetch_ohlcv.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fabb7eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… OHLCV saved: 68324 bars\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from requests.exceptions import ConnectionError\n",
    "from binance.client import Client\n",
    "from binance.exceptions import BinanceAPIException\n",
    "\n",
    "# â”€â”€ CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "API_KEY    = \"H2u6FGfNoMQTzzjjNtnRhMHJ5gQ2oPdWGV4RYNwGmyz2854hCS9pssxYm0nxEefn\"\n",
    "API_SECRET = \"u8ByWKpZX1sgTNVGZMzCwoHWkiQlRKIKMLnkNIBVtORNRx1vWlZNRsKvigHa2ylr\"\n",
    "SYMBOL     = \"BTCUSDT\"\n",
    "INTERVAL   = Client.KLINE_INTERVAL_1HOUR  # hourly\n",
    "START      = \"1 Jan, 2017\"\n",
    "DELAY      = 0.2\n",
    "MAX_RETRIES= 5\n",
    "\n",
    "client = Client(API_KEY, API_SECRET)\n",
    "\n",
    "# â”€â”€ SAFE WRAPPER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def retry_api(func, *args, **kwargs):\n",
    "    backoff = 1\n",
    "    for i in range(MAX_RETRIES):\n",
    "        try:\n",
    "            result = func(*args, **kwargs)\n",
    "            time.sleep(DELAY)\n",
    "            return result\n",
    "        except (ConnectionError, BinanceAPIException) as e:\n",
    "            print(f\"âš ï¸ {func.__name__} error ({e}), retry {i+1}/{MAX_RETRIES} in {backoff}s\")\n",
    "            time.sleep(backoff)\n",
    "            backoff *= 2\n",
    "    raise RuntimeError(f\"Failed after {MAX_RETRIES} retries in {func.__name__}\")\n",
    "\n",
    "def safe_get_klines(**kwargs):\n",
    "    return retry_api(client.get_klines, **kwargs)\n",
    "\n",
    "# â”€â”€ FETCH FUNCTION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def fetch_full_ohlcv(symbol, interval, start_str):\n",
    "    all_df   = []\n",
    "    last_ts  = pd.to_datetime(start_str)\n",
    "    while True:\n",
    "        klines = safe_get_klines(\n",
    "            symbol=symbol,\n",
    "            interval=interval,\n",
    "            startTime=int(last_ts.timestamp()*1000),\n",
    "            limit=1000\n",
    "        )\n",
    "        if not klines:\n",
    "            break\n",
    "        df = pd.DataFrame(klines, columns=[\n",
    "            \"open_time\",\"open\",\"high\",\"low\",\"close\",\"volume\",\n",
    "            \"close_time\",\"quote_asset_volume\",\"num_trades\",\n",
    "            \"taker_buy_base_vol\",\"taker_buy_quote_vol\",\"ignore\"\n",
    "        ])\n",
    "        df[\"open_time\"]  = pd.to_datetime(df[\"open_time\"], unit=\"ms\")\n",
    "        df = df.rename(columns={\"open_time\":\"timestamp\"})\n",
    "        all_df.append(df)\n",
    "        last_ts = df[\"timestamp\"].iloc[-1] + timedelta(milliseconds=1)\n",
    "        if last_ts >= datetime.utcnow():\n",
    "            break\n",
    "    return pd.concat(all_df, ignore_index=True)\n",
    "\n",
    "# â”€â”€ MAIN â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if __name__ == \"__main__\":\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    df = fetch_full_ohlcv(SYMBOL, INTERVAL, START)\n",
    "    df.to_csv(\"data2/ohlcv.csv\", index=False)\n",
    "    print(f\"âœ… OHLCV saved: {len(df)} bars\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7940c06c",
   "metadata": {},
   "source": [
    "Block 2 â€“ fetch_funding_rate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610d0781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Funding Rate saved: 6294 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elzandi Irfan Zikra\\AppData\\Local\\Temp\\ipykernel_12944\\4053613433.py:60: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  .resample(\"1H\").last()\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import time\n",
    "# import pandas as pd\n",
    "# from datetime import datetime, timedelta\n",
    "# from requests.exceptions import ConnectionError\n",
    "# from binance.client import Client\n",
    "# from binance.exceptions import BinanceAPIException\n",
    "\n",
    "# # â”€â”€ CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# API_KEY    = \"H2u6FGfNoMQTzzjjNtnRhMHJ5gQ2oPdWGV4RYNwGmyz2854hCS9pssxYm0nxEefn\"\n",
    "# API_SECRET = \"u8ByWKpZX1sgTNVGZMzCwoHWkiQlRKIKMLnkNIBVtORNRx1vWlZNRsKvigHa2ylr\"\n",
    "# SYMBOL     = \"BTCUSDT\"\n",
    "# START      = \"1 Jan, 2017\"\n",
    "# DELAY      = 0.2\n",
    "# MAX_RETRIES= 5\n",
    "\n",
    "# client = Client(API_KEY, API_SECRET)\n",
    "\n",
    "# # â”€â”€ SAFE WRAPPER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# def retry_api(func, *args, **kwargs):\n",
    "#     backoff = 1\n",
    "#     for i in range(MAX_RETRIES):\n",
    "#         try:\n",
    "#             res = func(**kwargs) if func.__name__!=\"client\" else func(*args, **kwargs)\n",
    "#             time.sleep(DELAY)\n",
    "#             return res\n",
    "#         except (ConnectionError, BinanceAPIException) as e:\n",
    "#             print(f\"âš ï¸ {func.__name__} error ({e}), retry {i+1}/{MAX_RETRIES} in {backoff}s\")\n",
    "#             time.sleep(backoff)\n",
    "#             backoff *= 2\n",
    "#     raise RuntimeError(f\"Failed after {MAX_RETRIES} retries in {func.__name__}\")\n",
    "\n",
    "# def safe_futures_funding_rate(**kwargs):\n",
    "#     return retry_api(client.futures_funding_rate, **kwargs)\n",
    "\n",
    "# # â”€â”€ FETCH FUNCTION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# def fetch_full_funding(symbol, start_str):\n",
    "#     all_df  = []\n",
    "#     last_ts = pd.to_datetime(start_str)\n",
    "#     while True:\n",
    "#         fr = safe_futures_funding_rate(\n",
    "#             symbol=symbol,\n",
    "#             startTime=int(last_ts.timestamp()*1000),\n",
    "#             limit=500\n",
    "#         )\n",
    "#         if not fr:\n",
    "#             break\n",
    "#         df = pd.DataFrame(fr)\n",
    "#         df[\"fundingTime\"] = pd.to_datetime(df[\"fundingTime\"], unit=\"ms\")\n",
    "#         df[\"fundingRate\"] = df[\"fundingRate\"].astype(float)\n",
    "#         all_df.append(df[[\"fundingTime\",\"fundingRate\"]])\n",
    "#         last_ts = df[\"fundingTime\"].iloc[-1] + timedelta(milliseconds=1)\n",
    "#         if last_ts >= datetime.utcnow():\n",
    "#             break\n",
    "\n",
    "#     df_full = pd.concat(all_df, ignore_index=True)\n",
    "#     df_hour = (\n",
    "#         df_full\n",
    "#         .set_index(\"fundingTime\")\n",
    "#         .resample(\"1H\").last()\n",
    "#         .dropna()\n",
    "#         .reset_index()\n",
    "#         .rename(columns={\"fundingTime\":\"timestamp\"})\n",
    "#     )\n",
    "#     return df_hour\n",
    "\n",
    "# # â”€â”€ MAIN â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# if __name__ == \"__main__\":\n",
    "#     os.makedirs(\"data\", exist_ok=True)\n",
    "#     df = fetch_full_funding(SYMBOL, START)\n",
    "#     df.to_csv(\"data2/funding_rate.csv\", index=False)\n",
    "#     print(f\"âœ… Funding Rate saved: {len(df)} records\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0663c8",
   "metadata": {},
   "source": [
    "Block 3 â€“ fetch_agg_trades.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6099c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fetch_agg_trades.py\n",
    "\n",
    "# import os\n",
    "# import time\n",
    "# import pandas as pd\n",
    "# from datetime import datetime\n",
    "# from requests.exceptions import ConnectionError\n",
    "# from binance.client import Client\n",
    "# from binance.exceptions import BinanceAPIException\n",
    "\n",
    "# # â”€â”€ CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# API_KEY    = \"H2u6FGfNoMQTzzjjNtnRhMHJ5gQ2oPdWGV4RYNwGmyz2854hCS9pssxYm0nxEefn\"\n",
    "# API_SECRET = \"u8ByWKpZX1sgTNVGZMzCwoHWkiQlRKIKMLnkNIBVtORNRx1vWlZNRsKvigHa2ylr\"\n",
    "# SYMBOL      = \"BTCUSDT\"\n",
    "# START       = \"1 Jan, 2017\"\n",
    "# DELAY       = 0.2\n",
    "# MAX_RETRIES = 5\n",
    "\n",
    "# client = Client(API_KEY, API_SECRET)\n",
    "\n",
    "# # â”€â”€ SAFE WRAPPER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# def retry_api(func, *args, **kwargs):\n",
    "#     backoff = 1\n",
    "#     for i in range(MAX_RETRIES):\n",
    "#         try:\n",
    "#             res = func(*args, **kwargs)\n",
    "#             time.sleep(DELAY)\n",
    "#             return res\n",
    "#         except (ConnectionError, BinanceAPIException) as e:\n",
    "#             print(f\"âš ï¸ {func.__name__} error ({e}), retry {i+1}/{MAX_RETRIES} in {backoff}s\")\n",
    "#             time.sleep(backoff)\n",
    "#             backoff *= 2\n",
    "#     raise RuntimeError(f\"Failed after {MAX_RETRIES} retries in {func.__name__}\")\n",
    "\n",
    "# def safe_get_aggregate_trades(**kwargs):\n",
    "#     return retry_api(client.get_aggregate_trades, **kwargs)\n",
    "\n",
    "# # â”€â”€ FETCH FUNCTION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# def fetch_full_agg_trades(symbol, start_str):\n",
    "#     all_trades = []\n",
    "#     last_id    = None\n",
    "#     start_ms   = int(pd.to_datetime(start_str).timestamp() * 1000)\n",
    "\n",
    "#     while True:\n",
    "#         if last_id is None:\n",
    "#             params = {\n",
    "#                 \"symbol\":    symbol,\n",
    "#                 \"startTime\": start_ms,\n",
    "#                 \"limit\":     500\n",
    "#             }\n",
    "#         else:\n",
    "#             params = {\n",
    "#                 \"symbol\": symbol,\n",
    "#                 \"fromId\":  last_id + 1,\n",
    "#                 \"limit\":   500\n",
    "#             }\n",
    "\n",
    "#         trades = safe_get_aggregate_trades(**params)\n",
    "#         if not trades:\n",
    "#             break\n",
    "\n",
    "#         df = pd.DataFrame(trades).rename(\n",
    "#             columns={\"a\": \"aggTradeId\", \"T\": \"tradeTime\", \"q\": \"qty\"}\n",
    "#         )\n",
    "#         df[\"tradeTime\"] = pd.to_datetime(df[\"tradeTime\"], unit=\"ms\")\n",
    "#         all_trades.append(df)\n",
    "#         last_id = df[\"aggTradeId\"].iloc[-1]\n",
    "\n",
    "#     df_full = pd.concat(all_trades, ignore_index=True)\n",
    "#     df_full[\"hour\"] = df_full[\"tradeTime\"].dt.floor(\"H\")\n",
    "#     df_hour = (\n",
    "#         df_full\n",
    "#         .groupby(\"hour\")\n",
    "#         .apply(lambda d: pd.Series({\n",
    "#             \"buy_vol\":  d.loc[~d[\"isBuyerMaker\"], \"qty\"].sum(),\n",
    "#             \"sell_vol\": d.loc[ d[\"isBuyerMaker\"], \"qty\"].sum()\n",
    "#         }))\n",
    "#         .reset_index()\n",
    "#         .rename(columns={\"hour\": \"timestamp\"})\n",
    "#     )\n",
    "#     return df_hour\n",
    "\n",
    "# # â”€â”€ MAIN â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# if __name__ == \"__main__\":\n",
    "#     os.makedirs(\"data\", exist_ok=True)\n",
    "#     df = fetch_full_agg_trades(SYMBOL, START)\n",
    "#     df.to_csv(\"data/agg_trades.csv\", index=False)\n",
    "#     print(f\"âœ… Agg Trades saved: {len(df)} hourly records\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3deca0c5",
   "metadata": {},
   "source": [
    "Block 4 â€“ fetch_interest_and_orderbook.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563fe983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Open Interest snapshot saved for 2025-06-08 08:00:00\n",
      "âœ… Order Book snapshot saved for 2025-06-08 08:00:00\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import time\n",
    "# import pandas as pd\n",
    "# from datetime import datetime\n",
    "# from binance.client import Client\n",
    "# from binance.exceptions import BinanceAPIException\n",
    "# from requests.exceptions import ConnectionError\n",
    "\n",
    "# # â”€â”€ CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# API_KEY    = \"H2u6FGfNoMQTzzjjNtnRhMHJ5gQ2oPdWGV4RYNwGmyz2854hCS9pssxYm0nxEefn\"\n",
    "# API_SECRET = \"u8ByWKpZX1sgTNVGZMzCwoHWkiQlRKIKMLnkNIBVtORNRx1vWlZNRsKvigHa2ylr\"\n",
    "# SYMBOL      = \"BTCUSDT\"\n",
    "# DELAY       = 0.2\n",
    "# MAX_RETRIES = 5\n",
    "\n",
    "# client = Client(API_KEY, API_SECRET)\n",
    "\n",
    "# def retry_api(func, **kwargs):\n",
    "#     backoff = 1\n",
    "#     for i in range(MAX_RETRIES):\n",
    "#         try:\n",
    "#             result = func(**kwargs)\n",
    "#             time.sleep(DELAY)\n",
    "#             return result\n",
    "#         except (ConnectionError, BinanceAPIException) as e:\n",
    "#             print(f\"âš ï¸ {func.__name__} error ({e}), retry {i+1}/{MAX_RETRIES} in {backoff}s\")\n",
    "#             time.sleep(backoff)\n",
    "#             backoff *= 2\n",
    "#     raise RuntimeError(f\"Failed after {MAX_RETRIES} retries in {func.__name__}\")\n",
    "\n",
    "# # â”€â”€ 1. ambil snapshot Open Interest â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# def get_open_interest(symbol):\n",
    "#     oi = retry_api(client.futures_open_interest, symbol=symbol)\n",
    "#     return float(oi[\"openInterest\"])\n",
    "\n",
    "# # â”€â”€ 2. ambil snapshot Order Book â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# def get_order_book(symbol, limit=100):\n",
    "#     ob = retry_api(client.get_order_book, symbol=symbol, limit=limit)\n",
    "#     bids = pd.DataFrame(ob[\"bids\"], columns=[\"price\",\"qty\"]).astype(float)\n",
    "#     asks = pd.DataFrame(ob[\"asks\"], columns=[\"price\",\"qty\"]).astype(float)\n",
    "#     return bids, asks\n",
    "\n",
    "# # â”€â”€ MAIN â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# if __name__ == \"__main__\":\n",
    "#     os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "#     now = datetime.utcnow().replace(minute=0, second=0, microsecond=0)\n",
    "\n",
    "#     # 1) Open Interest\n",
    "#     oi_val = get_open_interest(SYMBOL)\n",
    "#     df_oi  = pd.DataFrame([{\"timestamp\": now, \"openInterest\": oi_val}])\n",
    "#     # append (atau buat baru)\n",
    "#     oi_path = \"data/open_interest.csv\"\n",
    "#     if os.path.exists(oi_path):\n",
    "#         df_oi.to_csv(oi_path, mode=\"a\", header=False, index=False)\n",
    "#     else:\n",
    "#         df_oi.to_csv(oi_path, index=False)\n",
    "#     print(f\"âœ… Open Interest snapshot saved for {now}\")\n",
    "\n",
    "#     # 2) Order Book\n",
    "#     bids, asks = get_order_book(SYMBOL, limit=100)\n",
    "#     df_ob = pd.DataFrame([{\n",
    "#         \"timestamp\": now,\n",
    "#         \"bid_depth\": bids[\"qty\"].sum(),\n",
    "#         \"ask_depth\": asks[\"qty\"].sum(),\n",
    "#         \"top_bid\":   bids[\"price\"].iloc[0],\n",
    "#         \"top_ask\":   asks[\"price\"].iloc[0]\n",
    "#     }])\n",
    "#     ob_path = \"data/order_book.csv\"\n",
    "#     if os.path.exists(ob_path):\n",
    "#         df_ob.to_csv(ob_path, mode=\"a\", header=False, index=False)\n",
    "#     else:\n",
    "#         df_ob.to_csv(ob_path, index=False)\n",
    "#     print(f\"âœ… Order Book snapshot saved for {now}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eed6838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fetch_open_interest_klines.py\n",
    "\n",
    "# import os\n",
    "# import time\n",
    "# import random\n",
    "# import requests\n",
    "# import pandas as pd\n",
    "# from datetime import datetime, timedelta\n",
    "\n",
    "# # â”€â”€ CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# SYMBOL      = \"BTCUSDT\"\n",
    "# INTERVAL    = \"1h\"             # 1h, 4h, 1d, dll.\n",
    "# START       = \"2017-01-01\"     # tarik data sejak 1 Jan 2017\n",
    "# LIMIT       = 1500             # max record per request\n",
    "# DATA_DIR    = \"data\"\n",
    "# MAX_RETRIES = 5\n",
    "# DELAY       = 0.2              # detik antar request\n",
    "\n",
    "# os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# # â”€â”€ SAFE REQUEST â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# def safe_request(url, params):\n",
    "#     backoff = 1\n",
    "#     for attempt in range(1, MAX_RETRIES+1):\n",
    "#         try:\n",
    "#             r = requests.get(url, params=params, timeout=10)\n",
    "#             r.raise_for_status()\n",
    "#             # jitter agar pola tidak seragam\n",
    "#             time.sleep(DELAY + random.random()*0.1)\n",
    "#             return r.json()\n",
    "#         except Exception as e:\n",
    "#             print(f\"âš ï¸ Attempt {attempt}/{MAX_RETRIES} failed: {e}. Retrying in {backoff}sâ€¦\")\n",
    "#             time.sleep(backoff)\n",
    "#             backoff *= 2\n",
    "#     raise RuntimeError(f\"Failed to fetch after {MAX_RETRIES} retries\")\n",
    "\n",
    "# # â”€â”€ FETCH OPEN INTEREST KLINES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# def fetch_open_interest_klines(symbol, interval, start_str):\n",
    "#     url = \"https://fapi.binance.com/futures/data/openInterestKlines\"\n",
    "#     start_ts = pd.to_datetime(start_str)\n",
    "#     all_df   = []\n",
    "\n",
    "#     while True:\n",
    "#         params = {\n",
    "#             \"symbol\":    symbol,\n",
    "#             \"interval\":  interval,\n",
    "#             \"limit\":     LIMIT,\n",
    "#             \"startTime\": int(start_ts.timestamp() * 1000)\n",
    "#         }\n",
    "#         data = safe_request(url, params)\n",
    "#         if not data:\n",
    "#             break\n",
    "\n",
    "#         df = pd.DataFrame(data, columns=[\n",
    "#             \"open_time\", \"open_interest\", \"open\", \"high\", \"low\",\n",
    "#             \"close\", \"volume\", \"close_time\", \"quote_volume\", \"count\"\n",
    "#         ])\n",
    "#         df[\"open_time\"]     = pd.to_datetime(df[\"open_time\"], unit=\"ms\")\n",
    "#         df[\"open_interest\"] = df[\"open_interest\"].astype(float)\n",
    "#         df = df[[\"open_time\", \"open_interest\"]]\n",
    "#         all_df.append(df)\n",
    "\n",
    "#         last_ts = df[\"open_time\"].iloc[-1]\n",
    "#         start_ts = last_ts + timedelta(milliseconds=1)\n",
    "#         if start_ts >= datetime.utcnow():\n",
    "#             break\n",
    "\n",
    "#     return pd.concat(all_df, ignore_index=True)\n",
    "\n",
    "# # â”€â”€ MAIN â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# if __name__ == \"__main__\":\n",
    "#     print(\"â–¶ï¸ Fetching Open Interest historis via openInterestKlinesâ€¦\")\n",
    "#     df_oi = fetch_open_interest_klines(SYMBOL, INTERVAL, START)\n",
    "#     path  = os.path.join(DATA_DIR, \"open_interest_hist.csv\")\n",
    "#     df_oi.to_csv(path, index=False)\n",
    "#     print(f\"âœ… Saved {len(df_oi)} records to {path}\")\n",
    "#     print(f\"   Range: {df_oi['open_time'].min()} â†’ {df_oi['open_time'].max()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ca0e4c",
   "metadata": {},
   "source": [
    "On Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddc649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import time\n",
    "# import requests\n",
    "# import pandas as pd\n",
    "# from datetime import datetime\n",
    "\n",
    "# # â”€â”€ 1. LETAKKAN API KEY DI SINI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# API_KEY = \"YOUR_GLASSNODE_API_KEY\"      # <<<â€“â€“ letakkan API key Anda\n",
    "# ASSET   = \"BTC\"\n",
    "\n",
    "# # â”€â”€ 2. PARAMETER UMUM â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# BASE_URL = \"https://api.glassnode.com/v1/metrics\"\n",
    "# START    = \"2017-01-01\"                 # tarik data sejak 1 Jan 2017\n",
    "# END      = datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "# RES      = \"1h\"                         # interval 1 jam\n",
    "\n",
    "# # konversi ke UNIX timestamp (detik)\n",
    "# since = int(pd.to_datetime(START).timestamp())\n",
    "# until = int(pd.to_datetime(END).timestamp())\n",
    "\n",
    "# # definisi metrics yang ingin di-fetch\n",
    "# metrics = {\n",
    "#     \"active_addresses\":    \"addresses/active_count\",\n",
    "#     \"exchange_inflow\":     \"exchanges/inflow\",\n",
    "#     \"exchange_outflow\":    \"exchanges/outflow\",\n",
    "#     \"tx_count\":            \"transactions/count\",\n",
    "#     \"miner_exch_vol\":      \"transactions/transfers_volume_miners_to_exchanges\",\n",
    "#     \"whale_tx_count\":      \"transactions/transfers_exchanges_to_whales_count\"\n",
    "# }\n",
    "\n",
    "# os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# for name, path in metrics.items():\n",
    "#     url = f\"{BASE_URL}/{path}\"\n",
    "#     params = {\n",
    "#         \"a\":        ASSET,\n",
    "#         \"s\":        since,\n",
    "#         \"u\":        until,\n",
    "#         \"i\":        RES,\n",
    "#         \"api_key\":  API_KEY\n",
    "#     }\n",
    "#     print(f\"â–¶ï¸ Fetching {name} â€¦\")\n",
    "#     r = requests.get(url, params=params, timeout=30)\n",
    "#     r.raise_for_status()\n",
    "#     data = r.json()  # list of {\"t\":<unix>, \"v\":<value>}\n",
    "#     # ubah ke DataFrame\n",
    "#     df = pd.DataFrame(data)\n",
    "#     df[\"timestamp\"] = pd.to_datetime(df[\"t\"], unit=\"s\")\n",
    "#     df = df.rename(columns={\"v\": name}).drop(columns=[\"t\"])\n",
    "#     # simpan\n",
    "#     df.to_csv(f\"data/{name}.csv\", index=False)\n",
    "#     print(f\"âœ… Saved data/{name}.csv ({len(df)} rows)\")\n",
    "\n",
    "# print(\"ğŸ‰ Semua data on-chain per jam berhasil diambil ke folder `data/`\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
