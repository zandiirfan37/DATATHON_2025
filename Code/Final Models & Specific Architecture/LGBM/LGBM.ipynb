{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0590d058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging, joblib\n",
    "logging.getLogger('lightgbm').setLevel(logging.WARNING)\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os, contextlib, sys\n",
    "\n",
    "# Paths ke CSV split\n",
    "TRAIN_PATH = '/kaggle/input/data-btc/fix2/train.csv'\n",
    "VAL_PATH   = '/kaggle/input/data-btc/fix2/val.csv'\n",
    "TEST_PATH  = '/kaggle/input/data-btc/fix2/test.csv'\n",
    "\n",
    "# 1) Load splits\n",
    "df_tr = pd.read_csv(TRAIN_PATH, parse_dates=['timestamp']).drop(columns=['timestamp','close_time'])\n",
    "df_va = pd.read_csv(VAL_PATH,   parse_dates=['timestamp']).drop(columns=['timestamp','close_time'])\n",
    "df_te = pd.read_csv(TEST_PATH,  parse_dates=['timestamp']).drop(columns=['timestamp','close_time'])\n",
    "\n",
    "# 2) Constants\n",
    "horizons = {'1h':1,'2h':2,'3h':3,'6h':6,'12h':12,'1d':24,'3d':72,'7d':168,'15d':360,'30d':720}\n",
    "PERIOD   = 24\n",
    "FEATURES = ['close','trend','season']\n",
    "\n",
    "# 3) Helpers\n",
    "def prepare(df, h):\n",
    "    df2 = df.copy()\n",
    "    df2['label'] = df2['close'].shift(-h)\n",
    "    df2.dropna(subset=['label'], inplace=True)\n",
    "    df2.reset_index(drop=True, inplace=True)\n",
    "    return df2\n",
    "\n",
    "def fit_stl_quiet(series, period):\n",
    "    with open(os.devnull, 'w') as dn, contextlib.redirect_stderr(dn):\n",
    "        res = STL(series, period=period, robust=True).fit()\n",
    "    return res\n",
    "\n",
    "def walk_forward(history_df, test_df, model_params, use_tune, label):\n",
    "    history_close = history_df['close'].to_numpy()\n",
    "    history_label = history_df['label'].to_numpy()\n",
    "    preds, trues = [], []\n",
    "    pts = min(10, len(test_df))\n",
    "    for i in range(pts):\n",
    "        tc = test_df['close'].iloc[i]\n",
    "        full_close = np.append(history_close, tc)\n",
    "        stl = fit_stl_quiet(full_close, PERIOD)\n",
    "        trend, season = stl.trend, stl.seasonal\n",
    "        n_hist = len(history_close)\n",
    "        df_re = pd.DataFrame({\n",
    "            'close':  full_close[:n_hist],\n",
    "            'trend':  trend[:n_hist],\n",
    "            'season': season[:n_hist],\n",
    "            'label':  history_label\n",
    "        })\n",
    "        df_re['residual'] = df_re['label'] - (df_re['trend'] + df_re['season'])\n",
    "        Xr, yr = df_re[FEATURES], df_re['residual'].values\n",
    "\n",
    "        if use_tune:\n",
    "            mdl = LGBMRegressor(random_state=42, **model_params)\n",
    "        else:\n",
    "            mdl = LGBMRegressor(random_state=42)\n",
    "        mdl.fit(Xr, yr)\n",
    "\n",
    "        feat = pd.DataFrame({\n",
    "            'close':  [tc],\n",
    "            'trend':  [trend[n_hist]],\n",
    "            'season': [season[n_hist]]\n",
    "        })\n",
    "        rp = mdl.predict(feat)[0]\n",
    "        fc = trend[n_hist] + season[n_hist] + rp\n",
    "\n",
    "        preds.append(fc)\n",
    "        trues.append(test_df['label'].iloc[i])\n",
    "\n",
    "        history_close = np.append(history_close, tc)\n",
    "        history_label = np.append(history_label, trues[-1])\n",
    "\n",
    "    rmse = mean_squared_error(trues, preds, squared=False)\n",
    "    mape = mean_absolute_percentage_error(trues, preds)*100\n",
    "\n",
    "    plt.figure(figsize=(9,4))\n",
    "    plt.plot(trues, label='Actual')\n",
    "    plt.plot(preds, '--', label='Predicted')\n",
    "    plt.title(f'{label}: Actual vs Pred (10)')\n",
    "    plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "    print(f'{label}: RMSE={rmse:.2f}, MAPE={mape:.2f}%')\n",
    "    return rmse, mape\n",
    "\n",
    "def tune_lgbm(X, y):\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators',100,500),\n",
    "            'num_leaves':    trial.suggest_int('num_leaves',16,64),\n",
    "            'max_depth':     trial.suggest_int('max_depth',3,10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate',1e-3,1e-1,log=True),\n",
    "            'feature_fraction': trial.suggest_float('feature_fraction',0.6,1.0),\n",
    "            'bagging_fraction': trial.suggest_float('bagging_fraction',0.6,1.0),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples',5,30),\n",
    "            'verbose': -1, 'device':'gpu'\n",
    "        }\n",
    "        ms = []\n",
    "        tss = TimeSeriesSplit(n_splits=3)\n",
    "        for ti, va in tss.split(X):\n",
    "            m = LGBMRegressor(random_state=42, **params)\n",
    "            m.fit(X.iloc[ti], y[ti])\n",
    "            ms.append(mean_squared_error(y[va], m.predict(X.iloc[va])))\n",
    "        return np.mean(ms)\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=20, show_progress_bar=False)\n",
    "    return study.best_trial.params\n",
    "\n",
    "===== FASE 1: TRAIN → VAL (no tuning) =====\n",
    "print(\"===== FASE 1: TRAIN → VAL =====\")\n",
    "for label, h in tqdm(horizons.items(), desc='Phase1'):\n",
    "    df_tr_p = prepare(df_tr, h)\n",
    "    df_va_p = prepare(df_va, h)\n",
    "    stl_tr = fit_stl_quiet(df_tr_p['close'], PERIOD)\n",
    "    df_tr_p['trend'], df_tr_p['season'] = stl_tr.trend, stl_tr.seasonal\n",
    "    df_tr_p['residual'] = df_tr_p['label'] - (df_tr_p['trend']+df_tr_p['season'])\n",
    "    print(f'  [Eval] {label} on VAL:')\n",
    "    walk_forward(df_tr_p, df_va_p, model_params=None, use_tune=False, label=label)\n",
    "\n",
    "# ===== FASE 2: (TRAIN+VAL) → TEST (with tuning & save) =====\n",
    "print(\"\\n===== FASE 2: (TRAIN+VAL) → TEST =====\")\n",
    "for label, h in tqdm(horizons.items(), desc='Phase2'):\n",
    "    # prepare\n",
    "    df_hist_p = prepare(pd.concat([df_tr, df_va], ignore_index=True), h)\n",
    "    df_te_p   = prepare(df_te, h)\n",
    "\n",
    "    stl_hist = fit_stl_quiet(df_hist_p['close'], PERIOD)\n",
    "    df_hist_p['trend'], df_hist_p['season'] = stl_hist.trend, stl_hist.seasonal\n",
    "    df_hist_p['residual'] = df_hist_p['label'] - (df_hist_p['trend']+df_hist_p['season'])\n",
    "    Xhv, yhv = df_hist_p[FEATURES], df_hist_p['residual'].values\n",
    "\n",
    "    # tuning\n",
    "    print(f'  [Tune] {label}')\n",
    "    best_params = tune_lgbm(Xhv, yhv)\n",
    "    print(f'    best_lgbm = {best_params}')\n",
    "\n",
    "    # final train & save\n",
    "    final_model = LGBMRegressor(random_state=42, **best_params)\n",
    "    final_model.fit(Xhv, yhv)\n",
    "    save_path = f'/kaggle/working/LGBM_{label}.pkl'\n",
    "    joblib.dump(final_model, save_path)\n",
    "    print(f'    Saved model to {save_path}')\n",
    "\n",
    "    # evaluation\n",
    "    print(f'  [Eval] {label} on TEST:')\n",
    "    # override walk_forward to use final_model instead of retrain per step\n",
    "    preds, trues = [], []\n",
    "    history_close = df_hist_p['close'].to_numpy()\n",
    "    history_label = df_hist_p['label'].to_numpy()\n",
    "    pts = min(10, len(df_te_p))\n",
    "    for i in range(pts):\n",
    "        tc = df_te_p['close'].iloc[i]\n",
    "        full_close = np.append(history_close, tc)\n",
    "        stl = fit_stl_quiet(full_close, PERIOD)\n",
    "        trend, season = stl.trend, stl.seasonal\n",
    "        feat = pd.DataFrame({\n",
    "            'close':  [tc],\n",
    "            'trend':  [trend[len(history_close)]],\n",
    "            'season': [season[len(history_close)]]\n",
    "        })\n",
    "        rp = final_model.predict(feat)[0]\n",
    "        fc = trend[len(history_close)] + season[len(history_close)] + rp\n",
    "        preds.append(fc)\n",
    "        trues.append(df_te_p['label'].iloc[i])\n",
    "        history_close = np.append(history_close, tc)\n",
    "        history_label = np.append(history_label, trues[-1])\n",
    "\n",
    "    rmse = mean_squared_error(trues, preds, squared=False)\n",
    "    mape = mean_absolute_percentage_error(trues, preds)*100\n",
    "\n",
    "    plt.figure(figsize=(9,4))\n",
    "    plt.plot(trues, label='Actual')\n",
    "    plt.plot(preds, '--', label='Predicted')\n",
    "    plt.title(f'{label}: Actual vs Pred (10)')\n",
    "    plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "    print(f'{label}: RMSE={rmse:.2f}, MAPE={mape:.2f}%\\n')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
