{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0590d058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging, joblib, os, contextlib\n",
    "logging.getLogger('lightgbm').setLevel(logging.WARNING)\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paths ke CSV split\n",
    "TRAIN_PATH = '/kaggle/input/data-btc/fix2/train.csv'\n",
    "VAL_PATH   = '/kaggle/input/data-btc/fix2/val.csv'\n",
    "TEST_PATH  = '/kaggle/input/data-btc/fix2/test.csv'\n",
    "\n",
    "# Load splits\n",
    "df_tr = pd.read_csv(TRAIN_PATH, parse_dates=['timestamp']).drop(columns=['timestamp','close_time'])\n",
    "df_va = pd.read_csv(VAL_PATH,   parse_dates=['timestamp']).drop(columns=['timestamp','close_time'])\n",
    "df_te = pd.read_csv(TEST_PATH,  parse_dates=['timestamp']).drop(columns=['timestamp','close_time'])\n",
    "\n",
    "# Constants\n",
    "horizons = {'1h':1,'2h':2,'3h':3,'6h':6,'12h':12,'1d':24,'3d':72,'7d':168,'15d':360,'30d':720}\n",
    "PERIOD   = 24\n",
    "\n",
    "# Helper: buat label shift\n",
    "def prepare(df, h):\n",
    "    df2 = df.copy()\n",
    "    df2['label'] = df2['close'].shift(-h)\n",
    "    df2.dropna(subset=['label'], inplace=True)\n",
    "    df2.reset_index(drop=True, inplace=True)\n",
    "    return df2\n",
    "\n",
    "# Helper: STL silent\n",
    "def fit_stl_quiet(series, period=PERIOD):\n",
    "    with open(os.devnull, 'w') as dn, contextlib.redirect_stderr(dn):\n",
    "        return STL(series, period=period, robust=True).fit()\n",
    "\n",
    "# Helper: Optuna tuning\n",
    "def tune_lgbm(X, y):\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators',100,500),\n",
    "            'num_leaves':    trial.suggest_int('num_leaves',16,64),\n",
    "            'max_depth':     trial.suggest_int('max_depth',3,10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate',1e-3,1e-1,log=True),\n",
    "            'feature_fraction': trial.suggest_float('feature_fraction',0.6,1.0),\n",
    "            'bagging_fraction': trial.suggest_float('bagging_fraction',0.6,1.0),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples',5,30),\n",
    "            'verbose': -1, 'device':'gpu'\n",
    "        }\n",
    "        ms = []\n",
    "        tss = TimeSeriesSplit(n_splits=3)\n",
    "        for ti, va in tss.split(X):\n",
    "            m = LGBMRegressor(random_state=42, **params)\n",
    "            m.fit(X.iloc[ti], y[ti])\n",
    "            ms.append(mean_squared_error(y[va], m.predict(X.iloc[va])))\n",
    "        return np.mean(ms)\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=20, show_progress_bar=False)\n",
    "    return study.best_trial.params\n",
    "\n",
    "# Phase1: retrain per-step dengan 3 fitur\n",
    "def walk_forward_phase1(history_df, test_df, label):\n",
    "    history = history_df.copy()\n",
    "    history_close = history['close'].to_numpy()\n",
    "    preds, trues = [], []\n",
    "    pts = min(10, len(test_df))\n",
    "\n",
    "    for i in range(pts):\n",
    "        tc = test_df['close'].iloc[i]\n",
    "        full = np.append(history_close, tc)\n",
    "        stl = fit_stl_quiet(full)\n",
    "        trend, season = stl.trend, stl.seasonal\n",
    "        n = len(history)\n",
    "\n",
    "        # build df_re dari history\n",
    "        df_re = history.copy()\n",
    "        df_re['trend']    = trend[:n]\n",
    "        df_re['season']   = season[:n]\n",
    "        df_re['residual'] = df_re['label'] - (df_re['trend'] + df_re['season'])\n",
    "\n",
    "        Xr = df_re[['close','trend','season']]\n",
    "        yr = df_re['residual'].values\n",
    "\n",
    "        mdl = LGBMRegressor(random_state=42)\n",
    "        mdl.fit(Xr, yr)\n",
    "\n",
    "        feat = test_df.iloc[[i]].copy()\n",
    "        feat['trend']  = trend[n]\n",
    "        feat['season'] = season[n]\n",
    "        Xf = feat[['close','trend','season']]\n",
    "\n",
    "        rp = mdl.predict(Xf)[0]\n",
    "        fc = trend[n] + season[n] + rp\n",
    "\n",
    "        preds.append(fc)\n",
    "        trues.append(test_df['label'].iloc[i])\n",
    "\n",
    "        history = pd.concat([history, test_df.iloc[[i]]], ignore_index=True)\n",
    "        history_close = np.append(history_close, tc)\n",
    "\n",
    "    rmse = mean_squared_error(trues, preds, squared=False)\n",
    "    mape = mean_absolute_percentage_error(trues, preds) * 100\n",
    "\n",
    "    plt.figure(figsize=(9,4))\n",
    "    plt.plot(trues, label='Actual')\n",
    "    plt.plot(preds, '--', label='Predicted')\n",
    "    plt.title(f'{label} Phase1: RMSE={rmse:.2f}, MAPE={mape:.2f}%')\n",
    "    plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "# Phase2: predict with final model\n",
    "def walk_forward_phase2(history_df, test_df, model, feature_cols, label):\n",
    "    history = history_df.copy()\n",
    "    history_close = history['close'].to_numpy()\n",
    "    preds, trues = [], []\n",
    "    pts = min(10, len(test_df))\n",
    "\n",
    "    for i in range(pts):\n",
    "        tc = test_df['close'].iloc[i]\n",
    "        full = np.append(history_close, tc)\n",
    "        stl = fit_stl_quiet(full)\n",
    "        trend, season = stl.trend, stl.seasonal\n",
    "        n = len(history)\n",
    "\n",
    "        feat = test_df.iloc[[i]].copy()\n",
    "        feat['trend']  = trend[n]\n",
    "        feat['season'] = season[n]\n",
    "        Xf = feat[feature_cols]\n",
    "\n",
    "        rp = model.predict(Xf)[0]\n",
    "        fc = trend[n] + season[n] + rp\n",
    "\n",
    "        preds.append(fc)\n",
    "        trues.append(test_df['label'].iloc[i])\n",
    "\n",
    "        history = pd.concat([history, test_df.iloc[[i]]], ignore_index=True)\n",
    "        history_close = np.append(history_close, tc)\n",
    "\n",
    "    rmse = mean_squared_error(trues, preds, squared=False)\n",
    "    mape = mean_absolute_percentage_error(trues, preds) * 100\n",
    "\n",
    "    plt.figure(figsize=(9,4))\n",
    "    plt.plot(trues, label='Actual')\n",
    "    plt.plot(preds, '--', label='Predicted')\n",
    "    plt.title(f'{label} Phase2: RMSE={rmse:.2f}, MAPE={mape:.2f}%')\n",
    "    plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "# ===== FASE 1: TRAIN → VAL =====\n",
    "print(\"===== FASE 1: TRAIN → VAL =====\")\n",
    "for label, h in horizons.items():\n",
    "    df_tr_p = prepare(df_tr, h)\n",
    "    df_va_p = prepare(df_va, h)\n",
    "    stl = fit_stl_quiet(df_tr_p['close'])\n",
    "    df_tr_p['trend'], df_tr_p['season'] = stl.trend, stl.seasonal\n",
    "    df_tr_p['residual'] = df_tr_p['label'] - (df_tr_p['trend'] + df_tr_p['season'])\n",
    "    print(f'-- {label} --')\n",
    "    walk_forward_phase1(df_tr_p, df_va_p, label)\n",
    "\n",
    "# ===== FASE 2: (TRAIN+VAL) → TEST [1h & 30d] =====\n",
    "print(\"\\n===== FASE 2: (TRAIN+VAL) → TEST =====\")\n",
    "for label, h in {'1h':1, '30d':720}.items():\n",
    "    print(f\"\\n--- Horizon {label} ---\")\n",
    "    df_hist = prepare(pd.concat([df_tr, df_va], ignore_index=True), h)\n",
    "    df_test= prepare(df_te, h)\n",
    "\n",
    "    # STL + residual\n",
    "    stl = fit_stl_quiet(df_hist['close'])\n",
    "    df_hist['trend'], df_hist['season'] = stl.trend, stl.seasonal\n",
    "    df_hist['residual'] = df_hist['label'] - (df_hist['trend'] + df_hist['season'])\n",
    "\n",
    "    # drop semua label_*\n",
    "    feature_cols = [c for c in df_hist.columns\n",
    "                    if c not in ('label','residual') and not c.startswith('label_')]\n",
    "\n",
    "    X = df_hist[feature_cols]\n",
    "    y = df_hist['residual'].values\n",
    "\n",
    "    # tuning & train final\n",
    "    best = tune_lgbm(X, y)\n",
    "    print(\" best_params:\", best)\n",
    "    model = LGBMRegressor(random_state=42, **best)\n",
    "    model.fit(X, y)\n",
    "    joblib.dump(model, f'/kaggle/working/model_{label}.pkl')\n",
    "\n",
    "    # SHAP top-20\n",
    "    expl = shap.TreeExplainer(model)\n",
    "    sv   = expl.shap_values(X)\n",
    "    df_sv= pd.DataFrame(np.abs(sv), columns=feature_cols)\n",
    "    imp20 = df_sv.mean().sort_values(ascending=False).head(20)\n",
    "    print(\"\\nTop 20 SHAP importances:\")\n",
    "    print(imp20.to_string())\n",
    "\n",
    "    # evaluasi\n",
    "    walk_forward_phase2(df_hist, df_test, model, feature_cols, label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e597d39b",
   "metadata": {},
   "source": [
    "Shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c40aa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging, joblib, os, contextlib\n",
    "logging.getLogger('lightgbm').setLevel(logging.WARNING)\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1) Load data\n",
    "TRAIN_PATH = '/kaggle/input/data-btc/fix3/fix2/train.csv'\n",
    "VAL_PATH   = '/kaggle/input/data-btc/fix3/fix2/val.csv'\n",
    "TEST_PATH  = '/kaggle/input/data-btc/fix3/fix2/test.csv'\n",
    "\n",
    "df_tr = pd.read_csv(TRAIN_PATH, parse_dates=['timestamp']).drop(columns=['timestamp','close_time'])\n",
    "df_va = pd.read_csv(VAL_PATH,   parse_dates=['timestamp']).drop(columns=['timestamp','close_time'])\n",
    "df_te = pd.read_csv(TEST_PATH,  parse_dates=['timestamp']).drop(columns=['timestamp','close_time'])\n",
    "\n",
    "# 2) Helper functions\n",
    "def prepare(df, h):\n",
    "    df2 = df.copy()\n",
    "    df2['label'] = df2['close'].shift(-h)\n",
    "    df2.dropna(subset=['label'], inplace=True)\n",
    "    df2.reset_index(drop=True, inplace=True)\n",
    "    return df2\n",
    "\n",
    "def fit_stl_quiet(series, period=24):\n",
    "    with open(os.devnull, 'w') as dn, contextlib.redirect_stderr(dn):\n",
    "        return STL(series, period=period, robust=True).fit()\n",
    "\n",
    "def tune_lgbm(X, y):\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators',100,500),\n",
    "            'num_leaves':    trial.suggest_int('num_leaves',16,64),\n",
    "            'max_depth':     trial.suggest_int('max_depth',3,10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate',1e-3,1e-1,log=True),\n",
    "            'feature_fraction': trial.suggest_float('feature_fraction',0.6,1.0),\n",
    "            'bagging_fraction': trial.suggest_float('bagging_fraction',0.6,1.0),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples',5,30),\n",
    "            'verbose': -1, 'device':'gpu'\n",
    "        }\n",
    "        ms = []\n",
    "        tss = TimeSeriesSplit(n_splits=3)\n",
    "        for ti, va in tss.split(X):\n",
    "            m = LGBMRegressor(random_state=42, **params)\n",
    "            m.fit(X.iloc[ti], y[ti])\n",
    "            ms.append(mean_squared_error(y[va], m.predict(X.iloc[va])))\n",
    "        return np.mean(ms)\n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=20, show_progress_bar=False)\n",
    "    return study.best_trial.params\n",
    "\n",
    "def walk_forward(history_df, test_df, model, feature_cols, period=24):\n",
    "    history = history_df.copy()\n",
    "    history_close = history['close'].to_numpy()\n",
    "    preds, trues = [], []\n",
    "    pts = min(10, len(test_df))\n",
    "\n",
    "    for i in range(pts):\n",
    "        tc = test_df['close'].iloc[i]\n",
    "        full = np.append(history_close, tc)\n",
    "        stl = fit_stl_quiet(full, period)\n",
    "        trend, season = stl.trend, stl.seasonal\n",
    "        n = len(history)\n",
    "\n",
    "        feat = test_df.iloc[[i]].copy()\n",
    "        feat['trend']  = trend[n]\n",
    "        feat['season'] = season[n]\n",
    "        Xf = feat[feature_cols]\n",
    "\n",
    "        rp = model.predict(Xf)[0]\n",
    "        fc = trend[n] + season[n] + rp\n",
    "\n",
    "        preds.append(fc)\n",
    "        trues.append(test_df['label'].iloc[i])\n",
    "\n",
    "        history_close = np.append(history_close, tc)\n",
    "        history = pd.concat([history, test_df.iloc[[i]]], ignore_index=True)\n",
    "\n",
    "    rmse = mean_squared_error(trues, preds, squared=False)\n",
    "    mape = mean_absolute_percentage_error(trues, preds) * 100\n",
    "\n",
    "    plt.figure(figsize=(9,4))\n",
    "    plt.plot(trues, label='Actual')\n",
    "    plt.plot(preds, '--', label='Predicted')\n",
    "    plt.title(f'Forecast vs Actual (10) — RMSE={rmse:.2f}, MAPE={mape:.2f}%')\n",
    "    plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "\n",
    "# 3) FASE 2 — horizon 1h, 1d, 30d\n",
    "for label, h in {'1h':1, '1d':24, '30d':720}.items():\n",
    "    print(f\"\\n=== Horizon {label} ===\")\n",
    "\n",
    "    # a) siapkan data\n",
    "    df_hist = prepare(pd.concat([df_tr, df_va], ignore_index=True), h)\n",
    "    df_test = prepare(df_te, h)\n",
    "\n",
    "    # b) STL + residual sebagai target\n",
    "    stl = fit_stl_quiet(df_hist['close'])\n",
    "    df_hist['trend'], df_hist['season'] = stl.trend, stl.seasonal\n",
    "    df_hist['residual'] = df_hist['label'] - (df_hist['trend'] + df_hist['season'])\n",
    "\n",
    "    # c) tentukan feature_cols: drop label, residual, dan semua kolom label_*\n",
    "    feature_cols = [\n",
    "        c for c in df_hist.columns\n",
    "        if c not in ('label','residual') and not c.startswith('label_')\n",
    "    ]\n",
    "\n",
    "    # d) tuning & training final\n",
    "    X = df_hist[feature_cols]\n",
    "    y = df_hist['residual'].values\n",
    "    best = tune_lgbm(X, y)\n",
    "    print(\" best_params:\", best)\n",
    "\n",
    "    model = LGBMRegressor(random_state=42, **best)\n",
    "    model.fit(X, y)\n",
    "    joblib.dump(model, f'/kaggle/working/model_{label}.pkl')\n",
    "\n",
    "    # e) SHAP — top 20 mean(|SHAP|)\n",
    "    expl = shap.TreeExplainer(model)\n",
    "    sv   = expl.shap_values(X)\n",
    "    df_sv = pd.DataFrame(np.abs(sv), columns=feature_cols)\n",
    "    imp20 = df_sv.mean().sort_values(ascending=False).head(20)\n",
    "    print(\"\\nTop 20 SHAP importances:\")\n",
    "    print(imp20.to_string())\n",
    "\n",
    "    # f) evaluasi via walk_forward\n",
    "    walk_forward(df_hist, df_test, model, feature_cols)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
