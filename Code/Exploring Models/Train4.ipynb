{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43130e82",
   "metadata": {},
   "source": [
    "Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cc1ae94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Real-time Direct Multi-Horizon (24 sampel) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stabil     0.8571    1.0000    0.9231         6\n",
      "          up     1.0000    0.9444    0.9714        18\n",
      "\n",
      "    accuracy                         0.9583        24\n",
      "   macro avg     0.9286    0.9722    0.9473        24\n",
      "weighted avg     0.9643    0.9583    0.9593        24\n",
      "\n",
      "Confusion Matrix:\n",
      "[[17  1  0]\n",
      " [ 0  6  0]\n",
      " [ 0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 1. Load & index\n",
    "df = pd.read_csv(\n",
    "    \"C:/Python/Template/Data Science/DATATHON_2025/data/off_chain/off_chain_btc3.csv\",\n",
    "    parse_dates=[\"timestamp\"],\n",
    "    index_col=\"timestamp\"\n",
    ")\n",
    "\n",
    "# 2. Fokus horizon 1–24\n",
    "horizons = list(range(1,25))\n",
    "\n",
    "# 3. Hitung titik snapshot: baris ke-(N-24)\n",
    "N = len(df)\n",
    "snapshot_idx = N - 24 - 1  # zero-based index\n",
    "\n",
    "# 4. Split data:\n",
    "#    - Train: baris [0 .. N-24-1]\n",
    "#    - Snapshot (test): baris N-24-1\n",
    "train_df    = df.iloc[: N - 24]\n",
    "snapshot_df = df.iloc[[snapshot_idx]]   # shape (1, ...)\n",
    "\n",
    "# 5. Siapkan fitur numerik saja\n",
    "numeric    = df.select_dtypes(include=[np.number]).columns\n",
    "feature_cols = [c for c in numeric if not c.startswith(\"label_\")]\n",
    "\n",
    "X_train = (\n",
    "    train_df[feature_cols]\n",
    "    .replace([np.inf, -np.inf], np.nan)\n",
    "    .fillna(train_df[feature_cols].median())\n",
    ")\n",
    "X_snap  = (\n",
    "    snapshot_df[feature_cols]\n",
    "    .replace([np.inf, -np.inf], np.nan)\n",
    "    .fillna(train_df[feature_cols].median())\n",
    ")\n",
    "\n",
    "# 6. Ambil ground-truth 24 sinyal dari snapshot baris\n",
    "y_true = [ snapshot_df[f\"label_{h}h\"].values[0] for h in horizons ]\n",
    "\n",
    "# 7. Latih & infer direct multi-horizon\n",
    "y_pred = []\n",
    "for h in horizons:\n",
    "    # target training untuk model h\n",
    "    y_train = train_df[f\"label_{h}h\"]\n",
    "\n",
    "    clf = LGBMClassifier(\n",
    "        n_estimators=200,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbosity=-1\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # infer satu snapshot\n",
    "    y_pred.append(clf.predict(X_snap)[0])\n",
    "\n",
    "# 8. Evaluasi pada 24 sampel horizon\n",
    "print(\"=== Real-time Direct Multi-Horizon (24 sampel) ===\")\n",
    "print(classification_report(y_true, y_pred, digits=4))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred, labels=[\"up\",\"stabil\",\"down\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c0c19d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Direct Multi-Horizon pada 24 baris terakhir ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stabil     0.7391    0.9444    0.8293        18\n",
      "          up     0.0000    0.0000    0.0000         6\n",
      "\n",
      "    accuracy                         0.7083        24\n",
      "   macro avg     0.3696    0.4722    0.4146        24\n",
      "weighted avg     0.5543    0.7083    0.6220        24\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  6  0]\n",
      " [ 1 17  0]\n",
      " [ 0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 1. Load & index\n",
    "df = pd.read_csv(\n",
    "    \"C:/Python/Template/Data Science/DATATHON_2025/data/off_chain/off_chain_btc3.csv\",\n",
    "    parse_dates=[\"timestamp\"],\n",
    "    index_col=\"timestamp\"\n",
    ")\n",
    "\n",
    "# 2. Fokus horizon 1–24\n",
    "horizons = list(range(1, 25))\n",
    "N        = len(df)\n",
    "\n",
    "# 3. Split train/test\n",
    "train_df = df.iloc[: N - 24]    # semua baris kecuali 24 terakhir\n",
    "test_df  = df.iloc[N - 24 : N]  # 24 baris terakhir sebagai test set\n",
    "\n",
    "# 4. Siapkan fitur numerik saja\n",
    "numeric     = df.select_dtypes(include=[np.number]).columns\n",
    "feature_cols = [c for c in numeric if not c.startswith(\"label_\")]\n",
    "\n",
    "# 5. Pre–pro fitur\n",
    "X_train_full = (\n",
    "    train_df[feature_cols]\n",
    "    .replace([np.inf, -np.inf], np.nan)\n",
    "    .fillna(train_df[feature_cols].median())\n",
    ")\n",
    "X_test_full  = (\n",
    "    test_df[feature_cols]\n",
    "    .replace([np.inf, -np.inf], np.nan)\n",
    "    .fillna(train_df[feature_cols].median())\n",
    ")\n",
    "\n",
    "# 6. Direct multi-horizon: predict row i with model_h\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for h in horizons:\n",
    "    # a) Latih model_h menggunakan semua data valid untuk horizon h\n",
    "    y_train_h = train_df[f\"label_{h}h\"]\n",
    "    X_tr_h    = X_train_full.iloc[:-h]      # drop h bar terakhir agar label valid\n",
    "    y_tr_h    = y_train_h.iloc[:-h]\n",
    "    \n",
    "    clf = LGBMClassifier(\n",
    "        n_estimators=200,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbosity=-1\n",
    "    )\n",
    "    clf.fit(X_tr_h, y_tr_h)\n",
    "    \n",
    "    # b) Prediksi baris ke-(h) di test set (0-based idx = h-1)\n",
    "    x_to_pred = X_test_full.iloc[[h-1]]\n",
    "    pred_h    = clf.predict(x_to_pred)[0]\n",
    "    y_pred.append(pred_h)\n",
    "    \n",
    "    # c) Ambil ground-truth label_h pada baris ke-(h)\n",
    "    true_h = test_df[f\"label_{h}h\"].iloc[h-1]\n",
    "    y_true.append(true_h)\n",
    "\n",
    "# 7. Evaluasi 24 sampel\n",
    "print(\"=== Direct Multi-Horizon pada 24 baris terakhir ===\")\n",
    "print(classification_report(y_true, y_pred, digits=4))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred, labels=[\"up\", \"stabil\", \"down\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4354c60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 10-Fold Sliding CV (10×24×24 sampel) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down     0.3114    0.2098    0.2507      1263\n",
      "      stabil     0.6968    0.8413    0.7623      3876\n",
      "          up     0.1747    0.0644    0.0941       621\n",
      "\n",
      "    accuracy                         0.6191      5760\n",
      "   macro avg     0.3943    0.3719    0.3690      5760\n",
      "weighted avg     0.5560    0.6191    0.5781      5760\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  40  509   72]\n",
      " [ 101 3261  514]\n",
      " [  88  910  265]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 1. Load & index\n",
    "df = pd.read_csv(\n",
    "    \"C:/Python/Template/Data Science/DATATHON_2025/data/off_chain/off_chain_btc3.csv\",\n",
    "    parse_dates=[\"timestamp\"],\n",
    "    index_col=\"timestamp\"\n",
    ")\n",
    "\n",
    "# 2. Fokus horizon 1–24 dan trim 24 baris head/tail agar semua label valid\n",
    "max_h = 24\n",
    "df_trim = df.iloc[max_h : len(df) - max_h].copy()\n",
    "# now df_trim has no NaN in label_1h..label_24h\n",
    "\n",
    "# 3. Tentukan folds: 240 baris terakhir dari df_trim dibagi 10 fold × 24 baris\n",
    "group_size = 24\n",
    "n_groups   = 10\n",
    "trim_N     = len(df_trim)\n",
    "start      = trim_N - group_size * n_groups\n",
    "\n",
    "fold_indices = [\n",
    "    (start + i*group_size, start + (i+1)*group_size)\n",
    "    for i in range(n_groups)\n",
    "]\n",
    "\n",
    "# 4. Siapkan fitur kolom numerik saja\n",
    "numeric    = df_trim.select_dtypes(include=[np.number]).columns\n",
    "feature_cols = [c for c in numeric if not c.startswith(\"label_\")]\n",
    "\n",
    "# 5. Loop sliding‐window CV\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "\n",
    "for fold_i, (i_start, i_end) in enumerate(fold_indices):\n",
    "    # a) training = semua baris sebelum i_start\n",
    "    train_df = df_trim.iloc[:i_start]\n",
    "    test_df  = df_trim.iloc[i_start:i_end]\n",
    "    \n",
    "    # b) pre–pro fitur\n",
    "    X_train_full = (\n",
    "        train_df[feature_cols]\n",
    "        .replace([np.inf, -np.inf], np.nan)\n",
    "        .fillna(train_df[feature_cols].median())\n",
    "    )\n",
    "    X_test_full  = (\n",
    "        test_df[feature_cols]\n",
    "        .replace([np.inf, -np.inf], np.nan)\n",
    "        .fillna(train_df[feature_cols].median())\n",
    "    )\n",
    "    \n",
    "    # c) per horizon h, latih & infer untuk 24 baris test\n",
    "    for h in range(1, max_h+1):\n",
    "        # target training: label_h only up to valid row\n",
    "        y_train = train_df[f\"label_{h}h\"].iloc[:-h]\n",
    "        X_tr_h  = X_train_full.iloc[:-h]\n",
    "        \n",
    "        # latih model\n",
    "        clf = LGBMClassifier(\n",
    "            n_estimators=200,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbosity=-1\n",
    "        )\n",
    "        clf.fit(X_tr_h, y_train)\n",
    "        \n",
    "        # infer untuk tiap t di test_df\n",
    "        y_pred_h = clf.predict(X_test_full)\n",
    "        y_true_h = test_df[f\"label_{h}h\"].values\n",
    "        \n",
    "        # simpan\n",
    "        y_true_all.extend(y_true_h.tolist())\n",
    "        y_pred_all.extend(y_pred_h.tolist())\n",
    "\n",
    "# 6. Evaluasi keseluruhan\n",
    "print(\"=== 10-Fold Sliding CV (10×24×24 sampel) ===\")\n",
    "print(classification_report(y_true_all, y_pred_all, digits=4))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true_all, y_pred_all, labels=[\"up\",\"stabil\",\"down\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a67986ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1: rows 67988–68011 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down     0.2000    0.2857    0.2353         7\n",
      "      stabil     0.6923    0.5294    0.6000        17\n",
      "          up     0.0000    0.0000    0.0000         0\n",
      "\n",
      "    accuracy                         0.4583        24\n",
      "   macro avg     0.2974    0.2717    0.2784        24\n",
      "weighted avg     0.5487    0.4583    0.4936        24\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 0 0]\n",
      " [0 9 8]\n",
      " [1 4 2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 2: rows 68012–68035 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down     0.0000    0.0000    0.0000        11\n",
      "      stabil     0.5500    1.0000    0.7097        11\n",
      "          up     0.2500    0.5000    0.3333         2\n",
      "\n",
      "    accuracy                         0.5000        24\n",
      "   macro avg     0.2667    0.5000    0.3477        24\n",
      "weighted avg     0.2729    0.5000    0.3530        24\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 1  1  0]\n",
      " [ 0 11  0]\n",
      " [ 3  8  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 3: rows 68036–68059 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down     1.0000    0.3333    0.5000        12\n",
      "      stabil     0.6000    1.0000    0.7500        12\n",
      "\n",
      "    accuracy                         0.6667        24\n",
      "   macro avg     0.8000    0.6667    0.6250        24\n",
      "weighted avg     0.8000    0.6667    0.6250        24\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  0  0]\n",
      " [ 0 12  0]\n",
      " [ 0  8  4]]\n",
      "\n",
      "=== Fold 4: rows 68060–68083 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down     0.0000    0.0000    0.0000         4\n",
      "      stabil     0.7143    0.5556    0.6250        18\n",
      "          up     0.0000    0.0000    0.0000         2\n",
      "\n",
      "    accuracy                         0.4167        24\n",
      "   macro avg     0.2381    0.1852    0.2083        24\n",
      "weighted avg     0.5357    0.4167    0.4688        24\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  0  2]\n",
      " [ 0 10  8]\n",
      " [ 0  4  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 5: rows 68084–68107 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down     0.0000    0.0000    0.0000         0\n",
      "      stabil     0.9000    0.9000    0.9000        20\n",
      "          up     0.0000    0.0000    0.0000         4\n",
      "\n",
      "    accuracy                         0.7500        24\n",
      "   macro avg     0.3000    0.3000    0.3000        24\n",
      "weighted avg     0.7500    0.7500    0.7500        24\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  2  2]\n",
      " [ 0 18  2]\n",
      " [ 0  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 6: rows 68108–68131 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down     0.2222    0.6667    0.3333         3\n",
      "      stabil     0.8667    0.6842    0.7647        19\n",
      "          up     0.0000    0.0000    0.0000         2\n",
      "\n",
      "    accuracy                         0.6250        24\n",
      "   macro avg     0.3630    0.4503    0.3660        24\n",
      "weighted avg     0.7139    0.6250    0.6471        24\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  1  1]\n",
      " [ 0 13  6]\n",
      " [ 0  1  2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 7: rows 68132–68155 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stabil     0.8333    1.0000    0.9091        20\n",
      "          up     0.0000    0.0000    0.0000         4\n",
      "\n",
      "    accuracy                         0.8333        24\n",
      "   macro avg     0.4167    0.5000    0.4545        24\n",
      "weighted avg     0.6944    0.8333    0.7576        24\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  4  0]\n",
      " [ 0 20  0]\n",
      " [ 0  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 8: rows 68156–68179 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down     0.0000    0.0000    0.0000         2\n",
      "      stabil     0.8750    1.0000    0.9333        21\n",
      "          up     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.8750        24\n",
      "   macro avg     0.2917    0.3333    0.3111        24\n",
      "weighted avg     0.7656    0.8750    0.8167        24\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  1  0]\n",
      " [ 0 21  0]\n",
      " [ 0  2  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 9: rows 68180–68203 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down     1.0000    0.3750    0.5455         8\n",
      "      stabil     0.7619    1.0000    0.8649        16\n",
      "\n",
      "    accuracy                         0.7917        24\n",
      "   macro avg     0.8810    0.6875    0.7052        24\n",
      "weighted avg     0.8413    0.7917    0.7584        24\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  0  0]\n",
      " [ 0 16  0]\n",
      " [ 0  5  3]]\n",
      "\n",
      "=== Fold 10: rows 68204–68227 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down     0.0000    0.0000    0.0000         5\n",
      "      stabil     0.2500    1.0000    0.4000         6\n",
      "          up     0.0000    0.0000    0.0000        13\n",
      "\n",
      "    accuracy                         0.2500        24\n",
      "   macro avg     0.0833    0.3333    0.1333        24\n",
      "weighted avg     0.0625    0.2500    0.1000        24\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0 13  0]\n",
      " [ 0  6  0]\n",
      " [ 0  5  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 1. Load & index\n",
    "df = pd.read_csv(\n",
    "    \"C:/Python/Template/Data Science/DATATHON_2025/data/off_chain/off_chain_btc3.csv\",\n",
    "    parse_dates=[\"timestamp\"],\n",
    "    index_col=\"timestamp\"\n",
    ")\n",
    "\n",
    "# 2. Trim head/tail 24 bar agar semua label_1h..label_24h valid\n",
    "max_h   = 24\n",
    "df_trim = df.iloc[max_h : len(df) - max_h].copy()\n",
    "\n",
    "# 3. Setup sliding‐window groups (240 bar terakhir dibagi 10×24)\n",
    "group_size = 24\n",
    "n_groups   = 10\n",
    "N_trim     = len(df_trim)\n",
    "base_idx   = N_trim - group_size * n_groups\n",
    "fold_indices = [\n",
    "    (base_idx + i*group_size, base_idx + (i+1)*group_size)\n",
    "    for i in range(n_groups)\n",
    "]\n",
    "\n",
    "# 4. Siapkan feature columns\n",
    "numeric      = df_trim.select_dtypes(include=[np.number]).columns\n",
    "feature_cols = [c for c in numeric if not c.startswith(\"label_\")]\n",
    "\n",
    "# 5. Loop per‐batch dan per‐horizon, cetak metrik tiap batch\n",
    "for fold_i, (batch_start, batch_end) in enumerate(fold_indices, start=1):\n",
    "    # a) Data training hingga 24 jam sebelum batch_start\n",
    "    train_df = df_trim.iloc[:batch_start]\n",
    "    # b) Snapshot row tepat sebelum batch\n",
    "    snap_row = df_trim.iloc[[batch_start - 1]]\n",
    "    # c) Batch ground-truth = 24 bar dari batch_start..batch_end-1\n",
    "    batch_df = df_trim.iloc[batch_start:batch_end]\n",
    "    \n",
    "    # d) Prepro fitur\n",
    "    X_train_full = (\n",
    "        train_df[feature_cols]\n",
    "        .replace([np.inf, -np.inf], np.nan)\n",
    "        .fillna(train_df[feature_cols].median())\n",
    "    )\n",
    "    X_snap = (\n",
    "        snap_row[feature_cols]\n",
    "        .replace([np.inf, -np.inf], np.nan)\n",
    "        .fillna(train_df[feature_cols].median())\n",
    "    )\n",
    "    \n",
    "    # e) Prediksi & ground-truth per horizon untuk batch ini\n",
    "    y_true_group = []\n",
    "    y_pred_group = []\n",
    "    for h in range(1, max_h + 1):\n",
    "        # training mengabaikan h bar terakhir\n",
    "        y_train = train_df[f\"label_{h}h\"].iloc[:-h]\n",
    "        X_tr_h  = X_train_full.iloc[:-h]\n",
    "        \n",
    "        clf = LGBMClassifier(\n",
    "            n_estimators=200,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbosity=-1\n",
    "        )\n",
    "        clf.fit(X_tr_h, y_train)\n",
    "        \n",
    "        # infer horizon-h untuk snapshot\n",
    "        pred_h = clf.predict(X_snap)[0]\n",
    "        y_pred_group.append(pred_h)\n",
    "        \n",
    "        # ground-truth di bar batch_start-1+h\n",
    "        true_h = df_trim[f\"label_{h}h\"].iloc[batch_start - 1 + h]\n",
    "        y_true_group.append(true_h)\n",
    "    \n",
    "    # f) Print metrics untuk fold ini\n",
    "    print(f\"\\n=== Fold {fold_i}: rows {batch_start}–{batch_end-1} ===\")\n",
    "    print(classification_report(y_true_group, y_pred_group, digits=4))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_true_group, y_pred_group, labels=[\"up\",\"stabil\",\"down\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85248715",
   "metadata": {},
   "source": [
    "Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "705fdb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Overall Evaluation (240 samples) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down     0.2750    0.2115    0.2391        52\n",
      "      stabil     0.6974    0.8500    0.7662       160\n",
      "          up     0.2000    0.0357    0.0606        28\n",
      "\n",
      "    accuracy                         0.6167       240\n",
      "   macro avg     0.3908    0.3658    0.3553       240\n",
      "weighted avg     0.5479    0.6167    0.5697       240\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  1  22   5]\n",
      " [  0 136  24]\n",
      " [  4  37  11]]\n",
      "\n",
      "--- Model label_1h Evaluation (10 samples) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stabil     1.0000    1.0000    1.0000        10\n",
      "\n",
      "    accuracy                         1.0000        10\n",
      "   macro avg     1.0000    1.0000    1.0000        10\n",
      "weighted avg     1.0000    1.0000    1.0000        10\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0  0]]\n",
      "\n",
      "--- Model label_2h Evaluation (10 samples) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stabil     1.0000    1.0000    1.0000        10\n",
      "\n",
      "    accuracy                         1.0000        10\n",
      "   macro avg     1.0000    1.0000    1.0000        10\n",
      "weighted avg     1.0000    1.0000    1.0000        10\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0  0]]\n",
      "\n",
      "--- Model label_3h Evaluation (10 samples) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down     0.0000    0.0000    0.0000         1\n",
      "      stabil     0.9000    1.0000    0.9474         9\n",
      "\n",
      "    accuracy                         0.9000        10\n",
      "   macro avg     0.4500    0.5000    0.4737        10\n",
      "weighted avg     0.8100    0.9000    0.8526        10\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 0 0]\n",
      " [0 9 0]\n",
      " [0 1 0]]\n",
      "\n",
      "--- Model label_4h Evaluation (10 samples) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down     0.0000    0.0000    0.0000         2\n",
      "      stabil     0.6000    1.0000    0.7500         6\n",
      "          up     0.0000    0.0000    0.0000         2\n",
      "\n",
      "    accuracy                         0.6000        10\n",
      "   macro avg     0.2000    0.3333    0.2500        10\n",
      "weighted avg     0.3600    0.6000    0.4500        10\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 2 0]\n",
      " [0 6 0]\n",
      " [0 2 0]]\n",
      "\n",
      "--- Model label_5h Evaluation (10 samples) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down     0.0000    0.0000    0.0000         4\n",
      "      stabil     0.5000    1.0000    0.6667         5\n",
      "          up     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.5000        10\n",
      "   macro avg     0.1667    0.3333    0.2222        10\n",
      "weighted avg     0.2500    0.5000    0.3333        10\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 1 0]\n",
      " [0 5 0]\n",
      " [0 4 0]]\n",
      "\n",
      "--- Model label_6h Evaluation (10 samples) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down     0.0000    0.0000    0.0000         3\n",
      "      stabil     0.7000    1.0000    0.8235         7\n",
      "\n",
      "    accuracy                         0.7000        10\n",
      "   macro avg     0.3500    0.5000    0.4118        10\n",
      "weighted avg     0.4900    0.7000    0.5765        10\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 0 0]\n",
      " [0 7 0]\n",
      " [0 3 0]]\n",
      "\n",
      "--- Model label_7h Evaluation (10 samples) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down     0.0000    0.0000    0.0000         3\n",
      "      stabil     0.7000    1.0000    0.8235         7\n",
      "\n",
      "    accuracy                         0.7000        10\n",
      "   macro avg     0.3500    0.5000    0.4118        10\n",
      "weighted avg     0.4900    0.7000    0.5765        10\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 0 0]\n",
      " [0 7 0]\n",
      " [0 3 0]]\n",
      "\n",
      "--- Model label_8h Evaluation (10 samples) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down     0.0000    0.0000    0.0000         5\n",
      "      stabil     0.4000    1.0000    0.5714         4\n",
      "          up     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.4000        10\n",
      "   macro avg     0.1333    0.3333    0.1905        10\n",
      "weighted avg     0.1600    0.4000    0.2286        10\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 1 0]\n",
      " [0 4 0]\n",
      " [0 5 0]]\n",
      "\n",
      "--- Model label_9h Evaluation (10 samples) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down     0.0000    0.0000    0.0000         2\n",
      "      stabil     0.7000    1.0000    0.8235         7\n",
      "          up     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.7000        10\n",
      "   macro avg     0.2333    0.3333    0.2745        10\n",
      "weighted avg     0.4900    0.7000    0.5765        10\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 1 0]\n",
      " [0 7 0]\n",
      " [0 2 0]]\n",
      "\n",
      "--- Model label_10h Evaluation (10 samples) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down     0.0000    0.0000    0.0000         1\n",
      "      stabil     0.8000    1.0000    0.8889         8\n",
      "          up     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.8000        10\n",
      "   macro avg     0.2667    0.3333    0.2963        10\n",
      "weighted avg     0.6400    0.8000    0.7111        10\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 1 0]\n",
      " [0 8 0]\n",
      " [0 1 0]]\n",
      "\n",
      "--- Model label_11h Evaluation (10 samples) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down     0.0000    0.0000    0.0000         1\n",
      "      stabil     0.8000    1.0000    0.8889         8\n",
      "          up     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.8000        10\n",
      "   macro avg     0.2667    0.3333    0.2963        10\n",
      "weighted avg     0.6400    0.8000    0.7111        10\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 1 0]\n",
      " [0 8 0]\n",
      " [0 1 0]]\n",
      "\n",
      "--- Model label_12h Evaluation (10 samples) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stabil     0.9000    1.0000    0.9474         9\n",
      "          up     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9000        10\n",
      "   macro avg     0.4500    0.5000    0.4737        10\n",
      "weighted avg     0.8100    0.9000    0.8526        10\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 1 0]\n",
      " [0 9 0]\n",
      " [0 0 0]]\n",
      "\n",
      "--- Model label_13h Evaluation (10 samples) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down     0.0000    0.0000    0.0000         0\n",
      "      stabil     0.7500    0.7500    0.7500         8\n",
      "          up     0.0000    0.0000    0.0000         2\n",
      "\n",
      "    accuracy                         0.6000        10\n",
      "   macro avg     0.2500    0.2500    0.2500        10\n",
      "weighted avg     0.6000    0.6000    0.6000        10\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 2 0]\n",
      " [0 6 2]\n",
      " [0 0 0]]\n",
      "\n",
      "--- Model label_14h Evaluation (10 samples) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down     0.5000    0.5000    0.5000         2\n",
      "      stabil     0.7143    0.8333    0.7692         6\n",
      "          up     1.0000    0.5000    0.6667         2\n",
      "\n",
      "    accuracy                         0.7000        10\n",
      "   macro avg     0.7381    0.6111    0.6453        10\n",
      "weighted avg     0.7286    0.7000    0.6949        10\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1 1 0]\n",
      " [0 5 1]\n",
      " [0 1 1]]\n",
      "\n",
      "--- Model label_15h Evaluation (10 samples) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down     0.3333    1.0000    0.5000         1\n",
      "      stabil     0.8571    0.7500    0.8000         8\n",
      "          up     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.7000        10\n",
      "   macro avg     0.3968    0.5833    0.4333        10\n",
      "weighted avg     0.7190    0.7000    0.6900        10\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 1 0]\n",
      " [0 6 2]\n",
      " [0 0 1]]\n",
      "\n",
      "--- Model label_16h Evaluation (10 samples) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down     0.5000    0.5000    0.5000         2\n",
      "      stabil     0.7500    0.8571    0.8000         7\n",
      "          up     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.7000        10\n",
      "   macro avg     0.4167    0.4524    0.4333        10\n",
      "weighted avg     0.6250    0.7000    0.6600        10\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 1 0]\n",
      " [0 6 1]\n",
      " [0 1 1]]\n",
      "\n",
      "--- Model label_17h Evaluation (10 samples) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down     0.0000    0.0000    0.0000         3\n",
      "      stabil     0.5556    0.8333    0.6667         6\n",
      "          up     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.5000        10\n",
      "   macro avg     0.1852    0.2778    0.2222        10\n",
      "weighted avg     0.3333    0.5000    0.4000        10\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 1 0]\n",
      " [0 5 1]\n",
      " [0 3 0]]\n",
      "\n",
      "--- Model label_18h Evaluation (10 samples) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down     0.3333    0.3333    0.3333         3\n",
      "      stabil     0.6667    0.8000    0.7273         5\n",
      "          up     0.0000    0.0000    0.0000         2\n",
      "\n",
      "    accuracy                         0.5000        10\n",
      "   macro avg     0.3333    0.3778    0.3535        10\n",
      "weighted avg     0.4333    0.5000    0.4636        10\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 1 1]\n",
      " [0 4 1]\n",
      " [1 1 1]]\n",
      "\n",
      "--- Model label_19h Evaluation (10 samples) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down     0.2500    0.2500    0.2500         4\n",
      "      stabil     0.4000    0.6667    0.5000         3\n",
      "          up     0.0000    0.0000    0.0000         3\n",
      "\n",
      "    accuracy                         0.3000        10\n",
      "   macro avg     0.2167    0.3056    0.2500        10\n",
      "weighted avg     0.2200    0.3000    0.2500        10\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 1 2]\n",
      " [0 2 1]\n",
      " [1 2 1]]\n",
      "\n",
      "--- Model label_20h Evaluation (10 samples) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down     0.2000    0.3333    0.2500         3\n",
      "      stabil     0.4000    0.4000    0.4000         5\n",
      "          up     0.0000    0.0000    0.0000         2\n",
      "\n",
      "    accuracy                         0.3000        10\n",
      "   macro avg     0.2000    0.2444    0.2167        10\n",
      "weighted avg     0.2600    0.3000    0.2750        10\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 1 1]\n",
      " [0 2 3]\n",
      " [0 2 1]]\n",
      "\n",
      "--- Model label_21h Evaluation (10 samples) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down     0.0000    0.0000    0.0000         3\n",
      "      stabil     0.5000    0.6000    0.5455         5\n",
      "          up     0.0000    0.0000    0.0000         2\n",
      "\n",
      "    accuracy                         0.3000        10\n",
      "   macro avg     0.1667    0.2000    0.1818        10\n",
      "weighted avg     0.2500    0.3000    0.2727        10\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 1 1]\n",
      " [0 3 2]\n",
      " [1 2 0]]\n",
      "\n",
      "--- Model label_22h Evaluation (10 samples) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down     0.4000    0.6667    0.5000         3\n",
      "      stabil     0.6000    0.5000    0.5455         6\n",
      "          up     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.5000        10\n",
      "   macro avg     0.3333    0.3889    0.3485        10\n",
      "weighted avg     0.4800    0.5000    0.4773        10\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 1 0]\n",
      " [0 3 3]\n",
      " [0 1 2]]\n",
      "\n",
      "--- Model label_23h Evaluation (10 samples) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down     0.3333    0.6667    0.4444         3\n",
      "      stabil     0.6667    0.3333    0.4444         6\n",
      "          up     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.4000        10\n",
      "   macro avg     0.3333    0.3333    0.2963        10\n",
      "weighted avg     0.5000    0.4000    0.4000        10\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 1 0]\n",
      " [0 2 4]\n",
      " [1 0 2]]\n",
      "\n",
      "--- Model label_24h Evaluation (10 samples) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down     0.2500    0.3333    0.2857         3\n",
      "      stabil     0.3333    0.4000    0.3636         5\n",
      "          up     0.0000    0.0000    0.0000         2\n",
      "\n",
      "    accuracy                         0.3000        10\n",
      "   macro avg     0.1944    0.2444    0.2165        10\n",
      "weighted avg     0.2417    0.3000    0.2675        10\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 2 0]\n",
      " [0 2 3]\n",
      " [0 2 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Python\\Template\\Data Science\\DATATHON_2025\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 1. Load data & indexing\n",
    "df = pd.read_csv(\n",
    "    \"C:/Python/Template/Data Science/DATATHON_2025/data/off_chain/off_chain_btc3.csv\",\n",
    "    parse_dates=[\"timestamp\"], index_col=\"timestamp\"\n",
    ")\n",
    "\n",
    "# 2. Trim head/tail 24 bar agar semua label valid\n",
    "max_h   = 24\n",
    "df_trim = df.iloc[max_h : len(df) - max_h].copy()\n",
    "\n",
    "# 3. Prepare sliding‐window folds (240 bar terakhir → 10 batch × 24 bar)\n",
    "group_size = 24\n",
    "n_groups   = 10\n",
    "N_trim     = len(df_trim)\n",
    "base_idx   = N_trim - group_size * n_groups\n",
    "fold_indices = [\n",
    "    (base_idx + i*group_size, base_idx + (i+1)*group_size)\n",
    "    for i in range(n_groups)\n",
    "]\n",
    "\n",
    "# 4. Feature columns (numerik saja)\n",
    "numeric      = df_trim.select_dtypes(include=[np.number]).columns\n",
    "feature_cols = [c for c in numeric if not c.startswith(\"label_\")]\n",
    "\n",
    "# 5. Containers for evaluation\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "per_model = {h: {\"true\": [], \"pred\": []} for h in range(1, max_h+1)}\n",
    "\n",
    "# 6. Loop over 10 batches\n",
    "for fold_i, (batch_start, batch_end) in enumerate(fold_indices, start=1):\n",
    "    # a) Training pool = semua baris sebelum batch_start\n",
    "    train_df = df_trim.iloc[:batch_start]\n",
    "    # b) Snapshot row tepat sebelum batch_start\n",
    "    snap_row = df_trim.iloc[[batch_start - 1]]\n",
    "    # c) Batch rows ground-truth akan diisi horizon-wise\n",
    "    \n",
    "    # d) Preprocess fitur\n",
    "    X_train_full = (\n",
    "        train_df[feature_cols]\n",
    "        .replace([np.inf, -np.inf], np.nan)\n",
    "        .fillna(train_df[feature_cols].median())\n",
    "    )\n",
    "    X_snap = (\n",
    "        snap_row[feature_cols]\n",
    "        .replace([np.inf, -np.inf], np.nan)\n",
    "        .fillna(train_df[feature_cols].median())\n",
    "    )\n",
    "    \n",
    "    # e) Per-horizon direct forecasting untuk batch\n",
    "    for h in range(1, max_h+1):\n",
    "        # 1) Siapkan training data valid untuk Model_h\n",
    "        #    drop h bar terakhir agar label_h tersedia\n",
    "        X_tr_h = X_train_full.iloc[:-h]\n",
    "        y_tr_h = train_df[f\"label_{h}h\"].iloc[:-h]\n",
    "        \n",
    "        # 2) Latih model\n",
    "        clf = LGBMClassifier(\n",
    "            n_estimators=200, random_state=42,\n",
    "            n_jobs=-1, verbosity=-1\n",
    "        )\n",
    "        clf.fit(X_tr_h, y_tr_h)\n",
    "        \n",
    "        # 3) Infer one step → ramal baris dalam batch (offset h)\n",
    "        pred = clf.predict(X_snap)[0]\n",
    "        y_pred_all.append(pred)\n",
    "        per_model[h][\"pred\"].append(pred)\n",
    "        \n",
    "        # 4) Ambil ground-truth pada baris batch_start-1+h\n",
    "        true = df_trim[f\"label_{h}h\"].iloc[batch_start - 1 + h]\n",
    "        y_true_all.append(true)\n",
    "        per_model[h][\"true\"].append(true)\n",
    "\n",
    "# 7. Evaluasi keseluruhan (240 sampel)\n",
    "print(\"=== Overall Evaluation (240 samples) ===\")\n",
    "print(classification_report(y_true_all, y_pred_all, digits=4))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true_all, y_pred_all, labels=[\"up\",\"stabil\",\"down\"]))\n",
    "\n",
    "# 8. Evaluasi per-model (10 sampel per horizon)\n",
    "for h in range(1, max_h+1):\n",
    "    yt = per_model[h][\"true\"]\n",
    "    yp = per_model[h][\"pred\"]\n",
    "    print(f\"\\n--- Model label_{h}h Evaluation (10 samples) ---\")\n",
    "    print(classification_report(yt, yp, digits=4))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(yt, yp, labels=[\"up\",\"stabil\",\"down\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff80bdb6",
   "metadata": {},
   "source": [
    "100 baris\n",
    "N = 100\n",
    "\n",
    "model - label_1h = N-1\n",
    "model - label_2h = N-2\n",
    "...\n",
    "..\n",
    "model - label_24h = N-24\n",
    "model - label_72h = N-72\n",
    "\n",
    "baris ke 100 != label\n",
    "\n",
    "model_1h, model_2h, ..., model_24h.\n",
    "24 model prediksi baris ke 100 = 24 prediksi untuk 1 baris. \n",
    "\n",
    "interpretasi dari hasil prediksi tiap model berbeda.\n",
    "model_1h prediksi baris 100(jam 4 pagi) = stabil. artinya harga close jam 4 pagi diprediksi stabil. close jam 4 pagi = jam 5 tepat.\n",
    "model_2h prediksi baris 100(jam 4 pagi) = down. artinya harga close jam 5 pagi diprediksi down. close jam 5 pagi = jam 6 tepat.\n",
    "model_24h prediksi baris 100(jam 4 pagi) = up. artinya harga close jam 4 pagi keesokan harinya diprediksi down. close jam 4 pagi = jam 5 tepat(keesokan harinya)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
